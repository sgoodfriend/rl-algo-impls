Microrts-env16-80m-ent5-lr3c-mgn2-shaped-rew-nga-a100:
  &microrts-env16-80m-ent5-lr3c-mgn2-shaped-rew-nga-a100
  additional_keys_to_log:
    - microrts_stats
    - microrts_results
    - results
    - action_mask_stats
  algo_hyperparams:
    batch_size: 4608
    clip_range: 0.1
    clip_range_vf: null
    ent_coef: 0.005
    gradient_accumulation: false
    learning_rate: !!float 3e-4
    max_grad_norm: 2
    ppo2_vf_coef_halving: true
    vf_coef: 0.5
  checkpoints_kwargs:
    history_size: 2
  device_hyperparams:
    set_float32_matmul_precision: high
    use_deterministic_algorithms: false
  env_hyperparams:
    additional_win_loss_reward: false
    bots:
      workerRushAI: 6
      lightRushAI: 6
      coacAI: 6
      mayari: 6
    env_type: microrts
    make_kwargs:
      bot_envs_alternate_player: true
      map_paths:
        - maps/16x16/basesWorkers16x16.xml
      max_steps: 4000
      num_selfplay_envs: 72
      render_theme: 2
      reward_weight:
        - 10.0 # RAIWinLossRewardFunction
        - 1.0 # ResourceGatherRewardFunction
        - 1.0 # ProduceWorkerRewardFunction
        - 0.2 # ProduceBuildingRewardFunction
        - 1.0 # AttackRewardFunction
        - 4.0 # ProduceLightUnitRewardFunction
        - 5.25 # ProduceHeavyUnitRewardFunction
        - 6.0 # ProduceRangedUnitRewardFunction
        - 0.0 # ScoreRewardFunction
    map_paths:
      - maps/16x16/basesWorkers16x16A.xml
      - maps/16x16/TwoBasesBarracks16x16.xml
      - maps/8x8/basesWorkers8x8A.xml
      - maps/8x8/FourBasesWorkers8x8.xml
      - maps/NoWhereToRun9x8.xml
      - maps/16x16/EightBasesWorkers16x16.xml
    n_envs: 72
    play_checkpoints_kwargs:
      n_envs_against_checkpoints: 24
    score_reward_kwargs: null
    self_play_kwargs: null
    valid_sizes:
      - 16
  env_id: Microrts-squnet-map16
  eval_hyperparams: &env16-eval
    deterministic: false
    env_overrides:
      additional_win_loss_reward: false
      bots:
        coacAI: 2
        droplet: 2
        guidedRojoA3N: 2
        izanagi: 2
        lightRushAI: 2
        mayari: 2
        mixedBot: 2
        naiveMCTSAI: 2
        passiveAI: 2
        randomAI: 2
        randomBiasedAI: 2
        rojo: 2
        tiamat: 2
        workerRushAI: 2
      make_kwargs:
        bot_envs_alternate_player: false
        map_paths:
          - maps/16x16/basesWorkers16x16A.xml
        max_steps: 4000
        num_selfplay_envs: 0
        render_theme: 2
        reward_weight:
          - 1.0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
      map_paths: []
      n_envs: 28
      play_checkpoints_kwargs: null
      score_reward_kwargs: {}
      self_play_kwargs: {}
    max_video_length: 4000
    n_episodes: 28
    score_function: mean
    step_freq: !!float 5e6
  n_timesteps: !!float 80e6
  policy_hyperparams:
    actor_head_style: squeeze_unet
    additional_critic_activation_functions: []
    channels_per_level:
      - 128
      - 128
      - 128
    decoder_residual_blocks_per_level:
      - 2
      - 3
    deconv_strides_per_level:
      - - 2
        - 2
      - - 2
        - 2
    encoder_residual_blocks_per_level:
      - 3
      - 2
      - 4
    normalization: layer
    output_activation_fn: identity
    strides_per_level:
      - 4
      - 4
    subaction_mask:
      0:
        1: 1
        2: 2
        3: 3
        4: 4
        5: 4
        6: 5
  process_mode: async
  rollout_hyperparams:
    full_batch_off_accelerator: true
    gae_lambda: 0.95
    gamma: 0.999
    n_steps: 512
  worker_hyperparams:
    n_rollout_workers: 4
    n_inference_workers: 2

Microrts-env16-240m-ent5-lr3c-mgn2-shaped-rew-nga-a100:
  &microrts-env16-240m-ent5-lr3c-mgn2-shaped-rew-nga-a100
  <<: *microrts-env16-80m-ent5-lr3c-mgn2-shaped-rew-nga-a100
  n_timesteps: !!float 240e6

Microrts-env16-240m-ent5-lr3c-mgn2-info-rew-vf50-nga-a100:
  &microrts-env16-240m-ent5-lr3c-mgn2-info-rew-vf50-nga-a100
  additional_keys_to_log:
    - microrts_stats
    - microrts_results
    - results
    - action_mask_stats
  algo_hyperparams:
    &microrts-env16-240m-ent5-lr3c-mgn2-info-rew-vf50-nga-a100-algo
    batch_size: 4608
    clip_range: 0.1
    clip_range_vf: null
    ent_coef: 0.005
    gradient_accumulation: false
    learning_rate: 0.0003
    max_grad_norm: 2
    multi_reward_weights:
      - 1.0
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.0
    ppo2_vf_coef_halving: true
    vf_coef: 0.5
    vf_loss_fn: huber_loss
    vf_weights:
      - 1.0
      - 0.5
      - 0.5
      - 0.5
      - 0.5
      - 0.5
      - 0.5
      - 0.5
      - 0.5
  checkpoints_kwargs:
    history_size: 2
  device_hyperparams:
    set_float32_matmul_precision: high
    use_deterministic_algorithms: false
  env_hyperparams:
    &microrts-env16-240m-ent5-lr3c-mgn2-info-rew-vf50-nga-a100-env
    additional_win_loss_reward: false
    bots:
      coacAI: 6
      lightRushAI: 6
      mayari: 6
      workerRushAI: 6
    env_type: microrts
    info_rewards:
      episode_end: false
      info_paths:
        - - raw_rewards
          - ResourceGatherRewardFunction
        - - raw_rewards
          - ProduceWorkerRewardFunction
        - - raw_rewards
          - ProduceBuildingRewardFunction
        - - raw_rewards
          - AttackRewardFunction
        - - raw_rewards
          - ProduceLightUnitRewardFunction
        - - raw_rewards
          - ProduceHeavyUnitRewardFunction
        - - raw_rewards
          - ProduceRangedUnitRewardFunction
        - - raw_rewards
          - ScoreRewardFunction
    make_kwargs:
      bot_envs_alternate_player: true
      map_paths:
        - maps/16x16/basesWorkers16x16.xml
      max_steps: 4000
      num_selfplay_envs: 72
      render_theme: 2
      reward_weight:
        - 1.0
        - 0
        - 0
        - 0
        - 0
        - 0
        - 0
        - 0
        - 0
    map_paths:
      - maps/16x16/basesWorkers16x16A.xml
      - maps/16x16/TwoBasesBarracks16x16.xml
      - maps/8x8/basesWorkers8x8A.xml
      - maps/8x8/FourBasesWorkers8x8.xml
      - maps/NoWhereToRun9x8.xml
      - maps/16x16/EightBasesWorkers16x16.xml
    n_envs: 72
    normalize: true
    normalize_kwargs:
      clip_reward: 1
      emv_window_size: 5000000.0
      exponential_moving_mean_var_reward: true
      gamma_reward: 0.999
      norm_obs: false
      norm_reward: true
    play_checkpoints_kwargs:
      n_envs_against_checkpoints: 24
    score_reward_kwargs: null
    self_play_kwargs: null
    valid_sizes:
      - 16
  env_id: Microrts-squnet-map16
  eval_hyperparams:
    deterministic: false
    env_overrides:
      additional_win_loss_reward: false
      bots:
        coacAI: 2
        droplet: 2
        guidedRojoA3N: 2
        izanagi: 2
        lightRushAI: 2
        mayari: 2
        mixedBot: 2
        naiveMCTSAI: 2
        passiveAI: 2
        randomAI: 2
        randomBiasedAI: 2
        rojo: 2
        tiamat: 2
        workerRushAI: 2
      info_rewards: null
      make_kwargs:
        bot_envs_alternate_player: false
        map_paths:
          - maps/16x16/basesWorkers16x16A.xml
        max_steps: 4000
        num_selfplay_envs: 0
        render_theme: 2
        reward_weight:
          - 1.0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
      map_paths: []
      n_envs: 28
      play_checkpoints_kwargs: null
      score_reward_kwargs: {}
      self_play_kwargs: {}
    max_video_length: 4000
    n_episodes: 28
    only_checkpoint_best_policies: true
    score_function: mean
    skip_evaluate_at_start: true
    step_freq: !!float 10e6
  n_timesteps: !!float 240e6
  policy_hyperparams:
    actor_head_style: squeeze_unet
    additional_critic_activation_functions:
      - identity
      - identity
      - identity
      - identity
      - identity
      - identity
      - identity
      - identity
    channels_per_level:
      - 128
      - 128
      - 128
    decoder_residual_blocks_per_level:
      - 2
      - 3
    deconv_strides_per_level:
      - - 2
        - 2
      - - 2
        - 2
    encoder_residual_blocks_per_level:
      - 3
      - 2
      - 4
    normalization: layer
    output_activation_fn: identity
    shared_critic_head: true
    strides_per_level:
      - 4
      - 4
    subaction_mask:
      0:
        1: 1
        2: 2
        3: 3
        4: 4
        5: 4
        6: 5
  process_mode: async
  rollout_hyperparams:
    full_batch_off_accelerator: true
    gae_lambda: 0.95
    gamma: 0.999
    n_steps: 512
  worker_hyperparams:
    n_inference_workers: 3
    n_rollout_workers: 8

Microrts-env16-240m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100:
  &microrts-env16-240m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100
  <<: *microrts-env16-240m-ent5-lr3c-mgn2-info-rew-vf50-nga-a100
  algo_hyperparams:
    &microrts-env16-240m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100-algo
    <<: *microrts-env16-240m-ent5-lr3c-mgn2-info-rew-vf50-nga-a100-algo
    multi_reward_weights:
      - 1.0 # RAIWinLossRewardFunction
      - 0.1 # ResourceGatherRewardFunction
      - 0.05 # ProduceWorkerRewardFunction
      - 0.05 # ProduceBuildingRewardFunction
      - 0.1 # AttackRewardFunction
      - 0.2 # ProduceLightUnitRewardFunction
      - 0.2 # ProduceHeavyUnitRewardFunction
      - 0.2 # ProduceRangedUnitRewardFunction
      - 0.0 # ScoreRewardFunction

Microrts-bw16a-80m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100:
  &microrts-bw16a-80m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100
  <<: *microrts-env16-240m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100
  env_hyperparams: &microrts-bw16a-80m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100-env
    <<: *microrts-env16-240m-ent5-lr3c-mgn2-info-rew-vf50-nga-a100-env
    map_paths:
      - maps/16x16/basesWorkers16x16A.xml
  n_timesteps: !!float 80e6

Microrts-env16-240m-ent5d1-lr4d1-mgn2-05wb2lwr-vf50-nga-a100:
  &microrts-env16-240m-ent5d1-lr4d1-mgn2-05wb2lwr-vf50-nga-a100
  <<: *microrts-env16-240m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100
  algo_hyperparams:
    &microrts-env16-240m-ent5d1-lr4d1-mgn2-05wb2lwr-vf50-nga-a100-algo
    <<: *microrts-env16-240m-ent5-lr3c-mgn2-05wb2lwr-vf50-nga-a100-algo
    learning_rate: 0.0004
  hyperparam_transitions_kwargs:
    phases:
      - ent_coef: !!float 5e-3
        learning_rate: !!float 4e-4
      - ent_coef: !!float 1e-3
        learning_rate: !!float 1e-4
    durations: [0, 1, 0]
